Plan:
First two months reproducibility (small parts)
Next two months own Ideas
Last two months Experiments and Thesis

Ask questions to Microsoft
Fatemeh creates Server account, sends synthezised DataSet
Use python, LLMs: Mystral, Llama2
scikit learn for decision trees

Parts of the System:
Pattern Learner
Repair System
Ranker

pip install git+https://github.com/pidgeyusedgust/pyprose

lyra.dbs.uni-hannover.de
https://docs.google.com/spreadsheets/d/17qrfvEaUH93oPkz5x8p8EFx_gfnSVyuyyzxRoJhtCV4/edit#gid=685207987

Set threshhold to 10%

Weekly Meetings with Fatemeh
Monthly Meetings with Ziawasch

https://filezilla-project.org
https://www.digitalocean.com/community/tutorials/how-to-use-sftp-to-securely-transfer-files-with-a-remote-server

Pattern Learner: https://docs.python.org/3/library/re.html

If you are interested in using several LLMs with a unified endpoint but without the annoying auth or model switch steps, this GitHub repo might be a life saver. 
https://github.com/ollama/ollama
Pros: 
 - Unified endpoint(s)
 - Smooth switch of different models by just editing the HTTPRequest body
 - Speed OK (automatically enabled GPU acceleration)
 - Multimodal included with the same smooth calling method
Cons:
 - Limited number of models, yet sufficient for basic usage (e.g. there's no MiniCPM or some other specific models)
 - Not know if the models are always up to date
 - Didn't find any info about fine-tune support
It is now deployed on Lyra. The API endpoint is http://lyra.dbs.uni-hannover.de:11434/api/??? (??? = generate/embedding/other mentioned in the doc). LLaMA2 (speed ok-ish) and Mistral (somehow slower than LLAMA) are already downloaded and ready to use. There is no Web interface for now.

https://huggingface.co/ for fine tuning maybe ?!?

https://www.promptingguide.ai/de
https://arxiv.org/pdf/2310.09263

"Ind-674-PRO",
      "US-823-JUN",
      "US-238-JUN",
      "QUAL-47",
      "QUAL-21",
      "Zim-843-PRO",
      "Eng-781-JUN",
      "Aus-664-PRO",
      "QUAL-88",
      "Ind-473-JUN",
      "usa_837",
      "Eng-573-JUN",
      "Zim-392-PRO",
      "QUAL-10",
	  
cd Users/Jonas_Hoppe/Uni/Master_Informatik/MasterArbeit/DataVinci

https://www.digitalocean.com/community/tutorials/how-to-install-the-anaconda-python-distribution-on-debian-10

Limitations:
Only single Column semantic abstraction
Few shot Prompting -> Chain of Thought Prompting

https://github.com/BigDaMa/raha
https://github.com/LUH-DBS/holodetect
https://github.com/HoloClean/HoloClean

https://github.com/DerAbbadon/DataVinci

Just choose 20 out of the 78
Try out applying LLM before patterns
String constants and values only out of the column 
Skip isFormula isLogical, isText = Only alphabetic characters
https://github.com/D2IP-TUB/Matelda/blob/main/marshmallow_pipeline/column_grouping_module/data_type_features.py